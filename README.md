# ğŸª¨ Lithofacies Prediction Pipeline from Well Log Data

## ğŸ“Œ Overview  
This project implements a **machine learning pipeline** for **lithofacies prediction** using **well log data**.  
It integrates **data preprocessing**, **exploratory analysis**, and a **two-stage classification model** to accurately predict lithofacies from geophysical inputs.  
The workflow is documented both in a **Jupyter Notebook** and a **technical report** that provides in-depth analysis and results interpretation.


## ğŸš€ Features  
âœ… Automated data cleaning and preprocessing  
âœ… Stability-based filtering for robust data selection  
âœ… XGBoost-driven missing value imputation  
âœ… Comprehensive feature engineering and anomaly detection  
âœ… Two-stage classification pipeline (Binary â†’ Multi-Class)  
âœ… Comparative analysis of ML strategies  
âœ… Detailed visualizations and performance evaluation  


## ğŸ“¦ Requirements  
- pandas  
- numpy  
- scikit-learn  
- xgboost  
- catboost  
- matplotlib  
- seaborn  


## ğŸ“‚ Project Structure  
```
â”œâ”€â”€ Data/
â”‚ â””â”€â”€ train.csv
â”œâ”€â”€ Code/
â”‚ â””â”€â”€ Startegies.ipynb
â”‚ â””â”€â”€ Challenge_V1.ipynb
â”‚ â”€â”€ Challenge_V2.ipnb
â”œâ”€â”€ Reports/
â”‚ â””â”€â”€ Final_Report.pdf
â”‚ â””â”€â”€ Strategies_Report.pdf
â””â”€â”€ README.md
```


## ğŸ”§ Installation  

### **Clone the repository:**  
```
git clone https://github.com/your-repo/lithofacies-prediction.git
cd lithofacies-prediction
```

### **Install dependencies:**
```
pip install -r requirements.txt

```
## ğŸ“Š Usage

### ğŸ§¹ Data Preprocessing
Run the preprocessing cells in the notebook:
- âœ” Load raw well log data
- âœ” Clean and filter unstable records
- âœ” Handle missing values using XGBoost-based imputation
- âœ” Generate stability and feature summaries

### ğŸ“ˆ Exploratory Data Analysis (EDA)
- âœ” Visualize log distributions and correlations
- âœ” Identify unstable zones and anomalies
- âœ” Extract geophysical feature patterns

#### ğŸ§  Two-Stage Classification Model
- Stage 1: Binary Classification (XGBoost) -> Task: Shale (1) vs Non-Shale (0)
- Stage 2: Multi-Class Classification (CatBoost) -> Task: Predict lithofacies for Non-Shale samples

## ğŸ” Model Evaluation
- âœ” Compute classification metrics (Weighted F1-score)
- âœ” Generate confusion matrices and ROC Curves
- âœ” Compare performance across models and configurations

## ğŸ§© Methodology Summary
The pipeline follows a structured 9-step workflow:
- Data Loading & Cleaning
- Exploratory Data Analysis (EDA)
- Stability Filtering
- Train/Test Split
- XGBoost Imputation
- Feature Engineering
- Anomaly Detection
- Model Training (Two-Stage)
- Evaluation & Validation

For detailed methodology evolution and comparisons, refer to:

ğŸ“– Section 1.3 â€” â€œMethodology Evolution and Strategy Comparisonâ€ in Strategies_Report.pdf.

## ğŸ“Š Results
Key outcomes from the final workflow include:
- âœ” Accurate lithofacies classification with improved shale detection
- âœ” Robust handling of unstable and missing data
- âœ” Enhanced interpretability through feature importance visualization
- âœ” High reproducibility with structured, modular code

## ğŸ¤ Contributing
1. **Fork the repository**
2. **Create your feature branch** (`git checkout -b feature-branch`)
3. **Commit your changes** (`git commit -m 'Add new feature'`)
4. **Push to the branch** (`git push origin feature-branch`)
5. **Submit a pull request** ğŸ‰  

## ğŸ™Œ Acknowledgments
Data provided as part of my SLB Internship Challenge (or at Force-2020-Machine-Learning-competition: https://github.com/bolgebrygg/Force-2020-Machine-Learning-competition)

Special thanks to contributors and reviewers involved in the lithofacies analysis and interpretation.

## ğŸ“˜ About
Machine learning-based lithofacies prediction pipeline leveraging XGBoost and CatBoost, with a focus on data quality, geological interpretability, and model robustness.
